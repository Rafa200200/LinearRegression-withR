``{r}
# First, let's create some fictitious data to illustrate the concept of simple linear regression.
# Suppose we have an independent variable x and a dependent variable y.
# Generate 20 random values for x between 0 and 10.
set.seed(123) # to ensure reproducibility of results
x <- runif(20, 0, 10)
# Generate 20 values for y using a linear function with a slope of 2 and an intercept of 5, plus some random noise.
y <- 2 * x + 5 + rnorm(20, 0, 1)
# Now, let's plot the data on a scatter plot.
plot(x, y, main = "Scatter plot of the data", xlab = "x", ylab = "y")
# Let's try fitting a straight line to the data using the lm function (linear model).
# The formula is y ~ x, meaning that y is explained by x.
model <- lm(y ~ x)
# View the results of the model using the summary function.
summary(model)
# Let's try fitting a straight line to the data using the lm function (linear model).
# The formula is y ~ x, meaning that y is explained by x.
model <- lm(y ~ x)
# View the results of the model using the summary function.
summary(model)
# Now, let's add the fitted line to the scatter plot using the abline function.
abline(model, col = "red")
# Now, let's add the fitted line to the scatter plot using the abline function.
abline(model, col = "red")
# First, let's create some fictitious data to illustrate the concept of simple linear regression.
# Suppose we have an independent variable x and a dependent variable y.
# Generate 20 random values for x between 0 and 10.
set.seed(123) # to ensure reproducibility of results
x <- runif(20, 0, 10)
# Generate 20 values for y using a linear function with a slope of 2 and an intercept of 5, plus some random noise.
y <- 2 * x + 5 + rnorm(20, 0, 1)
# Open a new graphics device
dev.new()
# Now, let's plot the data on a scatter plot.
plot(x, y, main = "Scatter plot of the data", xlab = "x", ylab = "y")
# Let's try fitting a straight line to the data using the lm function (linear model).
# The formula is y ~ x, meaning that y is explained by x.
model <- lm(y ~ x)
# View the results of the model using the summary function.
summary(model)
# Now, let's add the fitted line to the scatter plot using the abline function.
abline(model, col = "red")
# Extract coefficients
intercept <- coef(modelo)[1]
# Extract coefficients
intercept <- coef(model)[1]
slope <- coef(model)[2]
# Add the regression line to the scatter plot using the lines function.
lines(x, predict(modelo), col = "red")
# Extract coefficients
intercept <- coef(model)[1]
slope <- coef(model)[2]
# Add the regression line to the scatter plot using the lines function.
lines(x, predict(model), col = "red")
# First, let's create some fictitious data to illustrate the concept of simple linear regression.
# Suppose we have an independent variable x and a dependent variable y.
# Generate 20 random values for x between 0 and 10.
set.seed(123) # to ensure reproducibility of results
x <- runif(20, 0, 10)
# Open a new graphics device
plot.new()
# Generate 20 values for y using a linear function with a slope of 2 and an intercept of 5, plus some random noise.
y <- 2 * x + 5 + rnorm(20, 0, 1)
# Now, let's plot the data on a scatter plot.
plot(x, y, main = "Scatter plot of the data", xlab = "x", ylab = "y")
# Extract coefficients
intercept <- coef(model)[1]
slope <- coef(model)[2]
# Add the regression line to the scatter plot using the lines function.
lines(x, predict(model), col = "red")
# First, let's create some fictitious data to illustrate the concept of simple linear regression.
# Suppose we have an independent variable x and a dependent variable y.
# Generate 20 random values for x between 0 and 10.
set.seed(123) # to ensure reproducibility of results
x <- runif(20, 0, 10)
# Generate 20 values for y using a linear function with a slope of 2 and an intercept of 5, plus some random noise.
y <- 2 * x + 5 + rnorm(20, 0, 1)
# Now, let's plot the data on a scatter plot.
plot(x, y, main = "Scatter plot of the data", xlab = "x", ylab = "y")
# Extract coefficients
intercept <- coef(model)[1]
slope <- coef(model)[2]
# Open a new graphics device
plot.new()
# Add the regression line to the scatter plot using the lines function.
lines(x, predict(model), col = "red")
# Extract coefficients
intercept <- coef(model)[1]
slope <- coef(model)[2]
# Now, let's plot the data on a scatter plot.
plot(x, y, main = "Scatter plot of the data", xlab = "x", ylab = "y")
# Add the regression line to the scatter plot using the lines function.
lines(x, predict(model), col = "red")
# Extract coefficients
intercept <- coef(model)[1]
slope <- coef(model)[2]
plot(x, y, main = "Scatter plot of the data", xlab = "x", ylab = "y")
# Add the regression line to the scatter plot using the lines function.
abline(model, col = "red")
# Extract coefficients
intercept <- coef(model)[1]
slope <- coef(model)[2]
plot(x, y, main = "Scatter plot of the data", xlab = "x", ylab = "y")
# Add the regression line to the scatter plot using the lines function.
abline(model, col = "red")
# Visualize the residuals using the plot function with the resid argument.
plot(model, which = 1, main = "Residual plot")
# Identify the outliers using the identify function, allowing us to click on points and see their indices.
identify(x, y)
plot(model, which = 1, main = "Residual plot")
# Identify the outliers using the identify function, allowing us to click on points and see their indices.
identify(x, y)
# Identify the outliers using the identify function, allowing us to click on points and see their indices.
identify(x, y)
plot(model, which = 1, main = "Residual plot")
# Identify the outliers using the identify function, allowing us to click on points and see their indices.
identify(x, y)
# View the x and y values of these points using the subset function.
subset(data.frame(x, y), row.names %in% c(8, 19, 20))
# View the x and y values of these points using the subset function.
subset(data.frame(x, y), row.names %in% c('8', '19', '20'))
# View the x and y values of these points using the subset function.
subset(data.frame(x, y), row.names(data.frame(x, y)) %in% c("8", "19", "18"))
# First, let's create some fictitious data to illustrate the concept of simple linear regression.
# Suppose we have an independent variable x and a dependent variable y.
# Generate 20 random values for x between 0 and 10.
set.seed(123) # to ensure reproducibility of results
x <- runif(20, 0, 10)
# Generate 20 values for y using a linear function with a slope of 2 and an intercept of 5, plus some random noise.
y <- 2 * x + 5 + rnorm(20, 0, 1)
# Now, let's plot the data on a scatter plot.
plot(x, y, main = "Scatter plot of the data", xlab = "x", ylab = "y")
# First, let's create some fictitious data to illustrate the concept of simple linear regression.
# Suppose we have an independent variable x and a dependent variable y.
# Generate 20 random values for x between 0 and 10.
set.seed(123) # to ensure reproducibility of results
x <- runif(20, 0, 10)
# Generate 20 values for y using a linear function with a slope of 2 and an intercept of 5, plus some random noise.
y <- 2 * x + 5 + rnorm(20, 0, 1)
# Now, let's plot the data on a scatter plot.
plot(x, y, main = "Scatter plot of the data", xlab = "x", ylab = "y")
# First, let's create some fictitious data to illustrate the concept of simple linear regression.
# Suppose we have an independent variable x and a dependent variable y.
# Generate 20 random values for x between 0 and 10.
set.seed(123) # to ensure reproducibility of results
x <- runif(20, 0, 10)
# Generate 20 values for y using a linear function with a slope of 2 and an intercept of 5, plus some random noise.
y <- 2 * x + 5 + rnorm(20, 0, 1)
# Now, let's plot the data on a scatter plot.
plot(x, y, main = "Scatter plot of the data", xlab = "x", ylab = "y")
# First, let's create some fictitious data to illustrate the concept of simple linear regression.
# Suppose we have an independent variable x and a dependent variable y.
# Generate 20 random values for x between 0 and 10.
set.seed(123) # to ensure reproducibility of results
x <- runif(20, 0, 10)
# Generate 20 values for y using a linear function with a slope of 2 and an intercept of 5, plus some random noise.
y <- 2 * x + 5 + rnorm(20, 0, 1)
# Now, let's plot the data on a scatter plot.
plot(x, y, main = "Scatter plot of the data", xlab = "x", ylab = "y")
# First, let's create some fictitious data to illustrate the concept of simple linear regression.
# Suppose we have an independent variable x and a dependent variable y.
# Generate 20 random values for x between 0 and 10.
set.seed(123) # to ensure reproducibility of results
x <- runif(20, 0, 10)
# Generate 20 values for y using a linear function with a slope of 2 and an intercept of 5, plus some random noise.
y <- 2 * x + 5 + rnorm(20, 0, 1)
# Now, let's plot the data on a scatter plot.
plot(x, y, main = "Scatter plot of the data", xlab = "x", ylab = "y")
# Let's try fitting a straight line to the data using the lm function (linear model).
# The formula is y ~ x, meaning that y is explained by x.
model <- lm(y ~ x)
# View the results of the model using the summary function.
summary(model)
# Extract coefficients
intercept <- coef(model)[1]
slope <- coef(model)[2]
plot(x, y, main = "Scatter plot of the data", xlab = "x", ylab = "y")
# Add the regression line to the scatter plot using the lines function.
abline(model, col = "red")
# Visualize the residuals using the plot function with the resid argument.
plot(model, which = 1, main = "Residual plot")
# Visualize the residuals using the plot function with the resid argument.
plot(model, which = 1, main = "Residual plot")
# View the x and y values of these points using the subset function.
subset(data.frame(x, y), row.names %in% c(2, 8, 18))
# View the x and y values of these points using the subset function.
subset(data.frame(x, y), row.names %in% c('2', '8', '18'))
# View the x and y values of these points using the subset function.
subset(data.frame(x, y), row.names(data.frame(x, y)) %in% c("8", "19", "20"))
# View the x and y values of these points using the subset function.
subset(data.frame(x, y), row.names(data.frame(x, y)) %in% c("2", "8", "18"))
# View the x and y values of these points using the subset function.
subset(data.frame(x, y), row.names(data.frame(x, y)) %in% c("7", "18", "19"))
# View the x and y values of these points using the subset function.
subset(data.frame(x, y), row.names(data.frame(x, y)) %in% c("8", "19", "20"))
# Remove the outliers from the model using the subset function with the exclude argument.
model_without_outliers <- lm(y ~ x, subset = -c(8, 19, 20))
# View the results of the new model using the summary function.
summary(model_without_outliers)
# Add the new fitted line to the scatter plot using the abline function with the lty argument.
abline(model_without_outliers, col = "blue", lty = 2)
plot(x, y, main = "Scatter plot of the data", xlab = "x", ylab = "y")
# Add the new fitted line to the scatter plot using the abline function with the lty argument.
abline(model_without_outliers, col = "blue", lty = 2)
plot(x, y, main = "Scatter plot of the data", xlab = "x", ylab = "y")
abline(model, col = "red")
# Add the new fitted line to the scatter plot using the abline function with the lty argument.
abline(model_without_outliers, col = "blue", lty = 2)
# Visualize the residuals of the new model using the plot function with the resid argument.
plot(model_without_outliers, which = 1, main = "Residual plot without outliers")
# First, let's create some fictitious data to illustrate the concept of simple linear regression.
# Suppose we have an independent variable x and a dependent variable y.
# Generate 20 random values for x between 0 and 10.
set.seed(123) # to ensure reproducibility of results
x <- runif(20, 0, 10)
# Generate 20 values for y using a linear function with a slope of 2 and an intercept of 5, plus some random noise.
y <- 2 * x + 5 + rnorm(20, 0, 1)
# Now, let's plot the data on a scatter plot.
plot(x, y, main = "Scatter plot of the data", xlab = "x", ylab = "y")
# Let's try fitting a straight line to the data using the lm function (linear model).
# The formula is y ~ x, meaning that y is explained by x.
model <- lm(y ~ x)
# View the results of the model using the summary function.
summary(model)
# Extract coefficients
intercept <- coef(model)[1]
slope <- coef(model)[2]
plot(x, y, main = "Scatter plot of the data", xlab = "x", ylab = "y")
# Add the regression line to the scatter plot using the lines function.
abline(model, col = "red")
# Visualize the residuals using the plot function with the resid argument.
plot(model, which = 1, main = "Residual plot")
# Identify the outliers using the identify function, allowing us to click on points and see their indices.
identify(x, y)
# Remove the outliers from the model using negative indexing.
model_without_outliers <- lm(y ~ x, data = data.frame(x, y)[-c(8, 19, 20), ])
# View the results of the new model using the summary function.
summary(model_without_outliers)
model_without_outliers <- lm(y ~ x, data = data.frame(x, y)[-c(8, 19, 20), ])
plot(x, y, main = "Scatter plot of the data", xlab = "x", ylab = "y")
abline(model, col = "red")
# Add the new fitted line to the scatter plot using the abline function with the lty argument.
abline(model_without_outliers, col = "blue", lty = 2)
# Visualize the residuals of the new model using the plot function with the resid argument.
plot(model_without_outliers, which = 1, main = "Residual plot without outliers")
